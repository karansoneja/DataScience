---
output: 
  pdf_document: 
    keep_md: yes
    keep_tex: true
    toc: true
    toc_depth: 2
    number_sections: true
    fig_width: 12
    fig_height: 6
    fig_caption: true
    includes: 
      in_header: my_header.tex
    highlight: tango
    df_print: kable # or kable or tibble
    citation_package: natbib

   
title: "Machine Learning Analysis applied to Investment strategies"
subtitle: |
  Université Paris 1 Panthéon-Sorbonne
  
  M2 IRFA Engineering of Financial Mathematics
  
  X5I22919 Data Science Software
  
  Module leader: Prof. Bertrand K. Hassani
  

author: 
- Antonio Malatesta^[E-mail\:antonio.malatesta@outlook.com] 
- Karan Soneja^[E-mail\:sonejakaran@gmail.com]
- Michele D'Ambrosio^[E-mail\:mi.dambrosio105@gmail.com]
 
bibliography: bibliography.bib
csl: econometrica.csl
fontsize: 11pt 


---

```{r package setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'D:/2017-2018/data_analysis/technical_analysis')
knitr::opts_chunk$set( message = FALSE, warning = FALSE )
# /usepackage{mathtools} #https://rpubs.com/davidpassmore/213041
library(quantmod)
library(PerformanceAnalytics)
library(png)
library(magrittr)
library(blotter)
library(knitr)
library(purrr)
library(kableExtra)
```



\newpage
# Introduction

The present report shows an implementation in R [^r_link] of three different Machine learning approaches to exploit historical stock price data for making predictions on the stocks' future price levels. We aim at understanding whether it is possible to obtain profitable trading indications leading to a  higher return than a passive strategy.  The remaining of the report is structured as follows. In Section 3, trading operations  are performed based on technical analysis indicators. In section 4, we use instead neural network analysis to develop an investment strategy, while in Section 5 a Random forest algorithm is implemented.

[^r_link]:https://cran.r-project.org/

# Data 

The data used in this report consists of the stock price of some of the 10 biggest publicly quoted French companies, as of September 2019 [^cac_40_ref].

[^cac_40_ref]: The full list here: https://live.euronext.com/en/product/indices/FR0003500008-XPAR/market-information

<!-- A TABLE -->

\begin{table}[ht]
\caption{Top ten firms in CAC40 by market cap, September 2019}
\centering
\begin{tabular}{|c|c|c|c|}
  \hline
Company	& MNEMO	 &	Sector  & Weight\% \\
  \hline
  TOTAL &	FP  & Oil and Gas &	9,54 \\
  LVMH &	MC  & Personal and Household Goods & 7,97 \\
  SANOFI & SAN  & Health Care &	7,54 \\
  AIRBUS & AIR  & Industrial Goods and Services &	5,47 \\
  L'OREAL	& OR  & Personal and Household Goods &	5,10 \\
  AIR LIQUIDE &	AI  & Chemicals &	4,40 \\
  DANONE &	BN  & Food and Beverage & 4,14 \\
  VINCI &	DG & Construction and Materials & 3,97 \\
  BNP PARIBAS ACT.A &	BNP  & Banks & 3,95 \\
  SAFRAN & SAF  & Industrial Goods and Services & 3,72 \\
   \hline
  \end{tabular}
\end{table} 


With the following command, we can download the daily open, high, low, close and adjusted prices, as well as the volume, of the stocks we consider in our analysis, from 28/12/2012 to 31/12/2018.

```{r eval= FALSE}
quantmod::getSymbols("COMPANY CODE", src="yahoo", 
                     from="2012-12-28", to="2018-12-31")
```

In some sections, we add economic and financial variables to test whether they can increase the predictive power of the analysis. The following table offers a detailed list of the variables considered.


```{r first_half,  echo=FALSE, include=TRUE}
col_econ= c("Economic\nFactors","Source")


econFact <- data.frame(
  EconomicFactors = 
  c( "Daily interest rate",
     "Daily Exchange rate\n(EUR/USD)", 
     "Political Stability (yearly)", 
     "CPI Infaltion (monthly)"),

  Source =
  c(  "sdw.ecb.europa.eu",
      "exchangerates.org",
      "databank.worldbank.org",  
      "www.inflation.eu"),    
  check.names = FALSE) %>%
  `colnames<-`(col_econ)
  # Source= ("sdw.ecb.europa.eu\nexchangerates.org\ndatabank.worldbank.org\nwww.inflation.eu"),


knitr::kable(econFact ,
             "latex", booktabs= TRUE, caption = "Additional economical variables" ,
              valign = 't') %>%
  #kableExtra::row_spec(1:14, extra_latex_after = "\\cline{3-3}") %>%
  #kableExtra::row_spec(6, hline_after = TRUE) %>%
  # kableExtra::column_spec(3, border_left = TRUE ) %>%
  # kableExtra::kable_styling(latex_options="scale_down") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") 
```


Our hypothesis is that factors like inflation and interest rate might have a big impact on companies' stock prices on a day-by-day basis. On the other hand, we consider financial statement data that change only on a yearly basis, checking whether black-box models can find connections between the prices and the variables over a long-term horizon.

```{r second_half, echo=FALSE, include=TRUE}
col_finan = c("Yearly Financial\nStatements Variables", "Source")

financFact <- data.frame(
  YearlyFinancialStatementsVariables = 
  c( "Dividend", "Revenue", 
  "Net income", "Basic earnings\nper share",
  "Diluted earnings\nper share", "Total assets",
  "Intangible assets", "PPE",
  "Cash", "Total equity", "Non current liability", 
  "Cash flows from operating activities", 
  "Net cash flows from\ninvesting activities", 
  "Net cash flows from\nfinancing activities",
  "Net cash and cash\nequivalents at end of period"
  ),
  
  Source =
  c( " ", " ",
  "dividenmax.com"," ",
  "airbus.com"," ",
  " airliquide.com", " ",
  "danone.com", " ", "vinci.com", " ",
  "invest.bnpparibas.com", " ", " "
  ),
  check.names = FALSE
) %>%
  `colnames<-`(col_finan)


knitr::kable( financFact,
             "latex", booktabs= TRUE, caption = "Additional financial statement variables" ,
              valign = 't') %>%
    kableExtra::kable_styling(latex_options = "HOLD_position") 
  
```

As a last disclaimer, the code shown in the report has only an explanatory purpose. We further attach the complete code to reproduce the analysis.

\newpage
# Technical analysis: implementation of a naive strategy in R

As @Brock1992 explain,  *technical analysis* (TA) is an "attempt to forecast prices by the study of past prices and a few other related summary statistics about security trading" (pag 2).  This practice however clashes with the Efficient Market Hypotesis lied out by @Fama1970 , according to which market prices incorporate all available information on the securities at any times. 



Despite Fama's paper, which soon got traction among academia, the work by @Taylor1992 reports that practioners in the world largest financial centres declare making use of Technical analysis, especially for intraday and short-term period trading. This revamped a large stream of research on the topic, to the point where complex optimization algorithms (namely, of the class of evolutionary algorithms) were introduced to get better predictions in terms of global optima search. For example, genetic programming is implemented to avoid the human bias in creating trading rules, letting the algorithms evaluate a series of rules implemented at each search stage, picking the best features and discarding the least performing ones. For a lengthier treatment on the topic, the reader can refer to @Neely1997, or the more recent @Mousavi2014 .


@Neftci1991 gives a proper formal charaterization of the main classes of technical analysis indicators. He claims that "any well-defined technical analysis rule has to pass the test of being a Markov time", otherwise "the procedure would be using future information in order to issue such signals" (pag. 8). Hence, relying heavily on chart analysis can be misleading. A class of signals that appear to be stopping times are those generated by moving average indicators, which are those we use in the present section.

One caveat one should always keep in mind when talking about technical analysis is that its predictive power can be biased upward by its intrinsic self-fulfilling feature: if agents believe that TA can have some predictive power, then following the trends will indeed let the predicted events happen, as all agents will implement similar decisions, given that they base their analysis on similar indicators.



## Technical analysis indicators


We will offer both a formal definition and a visual representation of each TA indicator used. In the following charts, prices are represented by the  so-called 'candlesticks'. The rectangular area will show the day open and close, whereas the wicks represent the day high and low. The green filling indicates that the security closed at a higher price than the opening, whereas orange indicates a negative performance on a day-basis. Trading volumes are also shown in the bottom part of the first chart. 



The first  indicator is the *simple moving average*. It is defined as 
\begin{equation} 
SMA = \displaystyle \sum_{t=1}^{n} \frac{x_t}{n} 
\end{equation} 

where $x_t =$ the t-th price observation, for   $t \in \{1,...,n\}$.

<!-- eval= FALSE to gain speed when compiling -->
```{r offline, eval=FALSE, echo= FALSE, include=FALSE }
# get the data
# set appropriate path for the csv to be found

  AIR.PA= 
    readr::read_csv("D:/2017-2018/data_analysis/technical_analysis/data/raw/AIR.PA_airbus.csv",
                    col_types = 
                      readr::cols(date =
                                    readr::col_date(format ="%d/%m/%Y" ))) %>% 
  timetk::tk_xts(date_var = date)
```

<!-- eval= FALSE to gain speed when compiling -->
```{r SMA crossing example,eval=FALSE, echo= FALSE, include=FALSE}

SMA_chart= chartSeries(AIR.PA, 
            type="matchsticks",
            name = "HLOC Candle chart and SMA, Air France",
            #subset='2013',
            theme=chartTheme('white'))

addSMA(n=50,on=1,col = "blue")
addSMA(n=200,on=1,col = "purple")

saveChart("png",width= 12, height = 6, units= "in", res= 300 )
          #path = "D:/2017-2018/data_analysis/technical_analysis/michele/output/linechart.png",
          # path can't be set. it goes to the working direcory
         
```


```{r shown SMA chart, eval= FALSE}
chartSeries(AIR.PA,# need '.PA' suffix for Paris CAC40
            type="matchsticks",
            name = "HLOC Candle chart and SMA, Air France",
            theme=chartTheme('white')) # chart setting

quantmod::addSMA(n=50,on=1,col = 'blue') # to overimpose SMA(50), in blue
quantmod::addSMA(n=200,on=1,col = 'purple') # TA functions from 'TTR' 
```

![Daily HLOC Chart price, with SMA(50) in blu, and SMA(200) in purple.]("D:/2017-2018/data_analysis/technical_analysis/report/HLOC Candle chart and SMA, Air France.png")

<!-- First time compiling on new machine, use following rather than above line   -->
<!-- ![Daily HLOC Chart price, with SMA(50) in blu, and SMA(200) in purple.](" /HLOC Candle chart and SMA, Air France.png") -->

The SMA is used to smooth out the price trends from the short-term fluctations. Usually, (at least) two SMA's of different time-lags are used together to generate trading signals. The short-term average crossing from below the long-term average is considered a buy signal, whereas a crossing in the other direction is taken as an indication to sell. One common choice for the lags are the 50- and the 200-days averages. One could also consider shorter time windows, to retain the short-term fluctations in the SMAs.

The second indicator is the **Relative Strength Index**, or RSI . 
It is computed as  
\begin{equation} 
RSI = 100 - \left( \frac{100}{(1 + \frac{\Delta_u}{\Delta_d} } \right) 
\end{equation}  where
$\Delta_u =$ Average of Upward Price Change, and
$\Delta_d =$ Average of Downward Price Change [^ref_rsi]. (See also @Hsu2016 for an example of different parametrizations.)


The RSI is an oscillator, since its value is in the range [0,100]. It gives indications on the **momentum**, that is, the "the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of a stock or other asset. [^rsi_def] " Generally,  $RSI>70$ is taken as an indication for a security to be overbought, whereas $RSI < 30$ has the opposite meaning.

```{r addRSI, eval= FALSE}
quantmod::addRSI(n=14, maType= 'SMA') 
# the RSI is shown, albeit not overimposed to the price pattern
```

<!-- eval= FALSE to gain speed when compiling -->
```{r RSI example,eval=FALSE, echo= FALSE, include=FALSE}
chartSeries(AIR.PA,
            type="matchsticks",
            name = "HLOC Candle chart and RSI, Air France",
            #subset='2013',
            theme=chartTheme('white'))

addRSI(n=14, maType= "SMA")

saveChart("png",width = 12, height = 6, units= "in", res= 300 )
```


![Daily HLOC Chart price with RSI(14)]("D:/2017-2018/data_analysis/technical_analysis/report/HLOC Candle chart and RSI, Air France.png")

<!-- change path on new machine -->
<!-- ![Daily HLOC Chart price with RSI(14)](" /HLOC Candle chart and RSI, Air France.png") -->

The third indicator are the **Bollinger Bands** [^boll_bands].
These are defined by the plot of a simple moving average, as defined below by the $\mu$, along with its standard deviation around it, defining the upper and lower bands. These are defined respectively as
\begin{equation}
B_u = MA(\mu, n) + m \cdot \sigma(\mu,n)
\end{equation} and
\begin{equation}
B_d = MA(\mu, n) - m \cdot \sigma(\mu,n)
\end{equation} 


with 

$HLC_t:=High_t +Low_t + Close_t$;

$\mu=  \frac{HLC_t}{3}$; 

$\sigma_n= \sqrt{\displaystyle \frac{\sum_{t=1}^{n} {(HLC_t-\mu)^2}}{n}}$ the standard deviation of HLC over n days; 

$n \in \mathbb{N^*}$ the number of days over which the SMA is computed;

$m \in \mathbb{N^*}$ the number of standard deviations used to create the width of the bands.



A common parametrization of this indicator is one with two-standard-deviation-wide bands around a 20-day simple moving average (i.e. $m=2$,$n=20$).

<!-- eval= FALSE to gain speed when compiling -->
```{r BBands example,eval=FALSE, echo= FALSE, include=FALSE}
chartSeries(AIR.PA,
            type="matchsticks",
            name = "HLOC Candle chart and Bollinger Bands, Air France", theme=chartTheme('white'))

addBBands(n=20, sd=2, maType= "SMA")

saveChart("png",width = 12, height = 6, units= "in", res= 300 )
```

```{r addBBands, eval=FALSE}
addBBands(n=20, sd=2, maType= "SMA") 
```

![Daily HLOC Chart price with Bollinger Bands (20,2)]("D:/2017-2018/data_analysis/technical_analysis/report/HLOC Candle chart and Bollinger Bands, Air France.png")
<!-- change path on new machine -->

## quantmod, blotter and quantstrat packages

  One important building block towards the implementation of Technical Analysis in R is the package quantmod [^quantmod], which allows the user to download stock prices data from Yahoo!, and to visualize different types of price charts, which are of great support in a first, rough analysis of the evolution of price trends over time. For the sake of offering a visual understanding of TA indicators, these functionalities were already exploited in the previuous paragraph, using the functions `quantmod::getSymbols()` and `quantmod::chartSeries`, along with `quantmod::addSMA`, `quantmod::addRSI`, and `quantmod::addBBands`.

Moreover, R supports a package named `quantstrat`, a "transaction-oriented infrastructure for constructing trading systems and simulation" [^quantstrat_overview]. However, this package counts several dependencies, and therefore we'll need our machine to be equipped with all these packages, as brilliantly shown in @Yu2019.

[^quantmod]:https://github.com/joshuaulrich/quantmod
[^rsi_def]:https://www.investopedia.com/terms/r/rsi.asp
[^ref_rsi]:https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/RSI 
[^quantstrat_overview]:https://www.rdocumentation.org/packages/quantstrat/versions/0.16.6   
[^boll_bands]: https://www.bollingerbands.com/


```{r show packages, eval=FALSE}

install.packages("quantmod")
install.packages("FinancialInstrument")
install.packages("PerformanceAnalytics")
install.packages("foreach")
install.packages("devtools")
devtools::install_github("braverock/blotter")
devtools::install_github("braverock/quanstrat")

```


## Portfolio management with quantstrat

<!-- In other words, whenever the condition encoded in the signal is evaluated as `TRUE`, a long or short position -depending on the specific signal observed- is taken. This strategy performance is also compared against a buy and hold strategy. -->

We build an actively managed portfolio made of the top five firms of the French CAC40 using six years of price data, from 2012-12-28 to 2018-12-31, for a total of 1534 trading days. The choice of the stocks fell simply on those we consider to be liquid enough, so that the chance of observing large sudden jumps in prices is low. In fact, fluctuations would negatively affect the TA predictive perfomance.

Starting with an initial capital of €100000, we will buy or sell 100 stocks of each equity, whenever some conditions on past prices are met. These conditions are later referred to as *signals*, and are linked to the  indicators  whose mathematical essence is shown in the previuos part. Our  main purpose is to create a plausible setup that, upon further improvements, can help an agent to infer some information on future prices movements based on past prices analysis. We will deliberately leave this model at a simplistic and unsophisticated stage, for the sake of outlying its main basic features with clarity. Nevertheless, several improvements would be needed before a proper real-life implementation. We will mention them in the  remaining of this chapter.


### Preliminary setup

We  first retrieve data from Yahoo! to the R global environment:

```{r eval=FALSE}
from ="2012-12-28"
to ="2018-12-31"
symbols = c("MC.PA","BN.PA","AIR.PA","BNP.PA","DG.PA" )
# the .PA label is needed to specify the Paris CAC40 stock exchange
quantmod::getSymbols(symbols,
                     from=from, to=to)
```

We then set up the strategy, the portfolio and the account objects:

```{r eval=FALSE}

initEq=100000 # capital to invest

strategy.st <- "strat.full.limit" # name the objects
portfolio.st <- "portf.full.limit"
account.st <- "acct.full.limit"

blotter::initPortf(portfolio.st, symbols) #initialize portfolio
blotter::initAcct(account.st, # need specifing also linked portfolio 
         portfolios=portfolio.st, 
         initEq = initEq) # capital level
quantstrat::initOrders(portfolio.st) # the orders 'container'
quantstrat::strategy(strategy.st, store=TRUE) # save our strategy in 
# the global environement

```

### Creating indicators 

As illustrated earlier, we make use of three simple indicators: simple moving average, relative strength index and Bollinger Bands.
The indicators will be linked to the startegy object previoulsy defined. The input dataframe is called *mktdata*, an object that will be created automatically when we validate the strategy.

```{r eval= FALSE, echo=TRUE}

quantstrat::add.indicator(
  strategy.st, name="SMA", # "name" must correspond to an R function
  arguments= list(x= quote(Cl(mktdata)), n=50), # input data are closing prices
  # set input data (mktdata) and indicator parameters through function 'arguments'
  label="sma50") ## unique reference 'mktdata' column name

add.indicator(strategy = strategy.st,
              name = 'RSI', # normally, we'll be using functions 
              # from the TTR package 
              arguments = list(price = quote(Cl(mktdata)), n=14), 
              # among the 'arguments', we need to set the 
              # parameter (number of days of the SMA) for the RSI
              label = 'rsi.14')

add.indicator(strategy = strategy.st,
              name= "BBands", 
              arguments = 
                list(HLC = quote(HLC(mktdata)),n=20, maType= "SMA", sd=2), 
              # BBands need High,Low and Closing Prices as an Input
              label = "bb.20.2")

```


### Combining indicators to create trading signals
The third step, after setting up the blotter objects and creating the indicators, is creating buy and sell signals out of an appropriate blend of indicators.
Below we offer a summary of the signals that will be used here.


```{r  echo= FALSE, include=TRUE}
col_names_sig= c(" Type of Signal","Signal","Execution")
signals <- data.frame(

  
  TypeOfSignal = 
  c( "Crossover","Crossover",
  "Threshold","Threshold",
  " Crossover &\nThreshold", " Crossover &\nThreshold",
  "Crossover","Crossover",
  " Crossover &\nThreshold", " Crossover &\nThreshold"
  ),

  Signal = 
  c("SMA(50)>SMA(200)", "SMA(50)<SMA(200)", 
  "RSI<30","RSI>70",
  "SMA(50)>SMA(200) & RSI<30","SMA(50)<SMA(200) & RSI>70", 
  "Closing > Upper BBand ", "Closing < Lower BBand",
  "Closing < Lower BBand &\nRSI<30", "Closing > Upper BBand &\nRSI>70"
  ),

  Execution = c(
    "NA ", "NA ", 
    "NA ", "NA ",
    "BUY ", "SELL ",
    "NA ", "NA ",
    "BUY ", "SELL "),
  check.names = FALSE
) %>%
  `colnames<-`(col_names_sig)


pander::pander(signals, caption = "Summary of signals and related trading executions",
               justify= "left", split.table= Inf)

```  

  
Despite having defined ten signals, only four of these will trigger actual execution orders. This is because it looks safer to rely on a mixed signal - i.e. one making use of more than one indicator - rather than only on a simple one. 

Here is some code showing how a mixed signal is created, based on the evaluation of two simple ones, which in turn may have different level of complexities, depending on the kind of indicators used to build them. Notice that the function `sigFormula` can take more than two arguments, evaluating therefore several conditions at once.

```{r eval=FALSE}

## 'Bull market' (i.e. market considered underpriced --> indication to buy) 
# if SMA50>SMA200
quantstrat::add.signal(
  strategy.st, name="sigCrossover", ## "name" is a function taking on
           # specific arguments 
           arguments= list(columns=c("sma50","sma200"),relationship="gt"), 
            # 'columns' refers to the indicators defined above
           label="smabuy") # 'label' will be the reference for 
# the execution phase hereafter.

## Specifies all instance when RSI is below 30 
## (indication of asset being oversold)
add.signal(strategy.st, name = "sigThreshold",
           arguments = 
             list(column = "rsi.14", threshold = 30, relationship = "lt", 
                  cross = TRUE), # signals 
           label = "rsi14buy")

## sigFormula which indicates that both smabuy and rsi14buy must evaluate TRUE.
add.signal(strategy.st, name = "sigFormula",
           arguments = list(formula = "smabuy & rsi14buy",cross = TRUE),
           # notice that the formula is evaluating two booleans 
           label = "entry1") 
```



### Executing tradings

The very last step of our strategy will be defining the trading operations to execute, once the relevant signals are observed. As shown in Table 4, only four signals trigger an order execution. We define accordingly four trading execution rules.


``` {r eval= FALSE}

## Enter the position when SMA(50)>SMA(200), and the RSI<30
quantstrat::add.rule(
  strategy.st, name = "ruleSignal",
         arguments = list(sigcol = "entry1", sigval = TRUE,
                          orderqty = 1000, ordertype = "market",
                          orderside = "long", replace = FALSE,
                          prefer = "Open", 
                          tradeSize = tradesize, maxSize = tradesize),
         type = "enter")  


## Exit the position when SMA(50)<SMA(200), and the RSI>70
add.rule(strategy.st, name = "ruleSignal",
         arguments = list(sigcol = "exit1", sigval = TRUE,
                          orderqty = -1000 , ordertype = "market",
                          orderside = "long", replace = FALSE,
                          prefer = "Open", 
                          tradeSize = tradesize, 
                          maxSize = tradesize),
         type = "exit") 


## Enter the position when (Closing price < Lower BBand) and RSI<30
add.rule(strategy = strategy.st, name= 'ruleSignal',
         arguments = list(sigcol = "entry2", sigval= TRUE,
                          orderqty = 1000, ordertype= 'market', 
                          orderside= NULL,threshold=NULL ), 
         type= "enter")


## Exit the position when (Closing price > Upper BBand) and RSI>70  
add.rule(strategy = strategy.st, name= 'ruleSignal',
         arguments = list(sigcol = "exit2", sigval= TRUE,
                          orderqty = -1000, ordertype= 'market', orderside= NULL,
                          threshold=NULL ),  
         type= "exit")
```

###  Running the model 
At this stage, we are ready to run our model. It is safer to check first whether the code for the strategy we seek to implement is 'bug-free'. To do this, we run the `quantstrat::applyStrategy` command within the `base::try` function, which allows to "run an expression that might fail and allow the user's code to handle error-recovery" [^try_func_ref].

[^try_func_ref]:  https://stat.ethz.ch/R-manual/R-devel/library/base/html/try.html


```{r NaN, eval= FALSE}
testing_strat <- base::try( quantstrat::applyStrategy(strategy.st,
                        portfolios=portfolio.st ))
## try is a function in one of the basis R packages

## We test whether our entire startegy was coded correctly 
```

```{r 5.00, echo=FALSE,  include= TRUE }
  source("D:/2017-2018/data_analysis/technical_analysis/michele/code_quantmod/5.00.rollout.R")

```

```{r 5.01 & 5.02, echo=FALSE, include= TRUE}
 source("D:/2017-2018/data_analysis/technical_analysis/michele/code_quantmod/5.01.rollout.R")

 source("D:/2017-2018/data_analysis/technical_analysis/michele/code_quantmod/5.02.rollout.R")

```


Since the strategy appears to run smoothly, we can update our portfolio and account to register the transactions and variations in the level of capital owned. We are now ready to extract the data on the performance, in the form of summary statistics and charts. Unfortunately, it seems that, due to an apparently still unfixed bug in the quantstrat package [^timestamps_error], it is not possible to export the strategy log. This is why we kept it printed to screen, as a full output of the command that runs the relevant strategy implementation script. 

[^timestamps_error]: https://github.com/braverock/quantstrat/issues/57


### Performance evaluation

As summarized in the first line of Table 5, our strategy tested on a five-year panel with five
stocks seems ‘conservative’, in that the maximum number of tradings on a stock is 17 (for MC.PA), with an average of roughly 12 across the five stocks. This may be due to the usage of long-term SMAs, which incorporate a low level of volatility.
As the table below shows, for three out of five stocks, the strategy net performance is negative. In particular, trading on LVHM register a loss above €50000. On the other hand, the strategy yields a positive return for Total and Sanofi. The lines "Percent.Positive" and "Percent.Negative", combined with "Num.Trades", gives an idea of how many open positions were closed during the observed time frame, and if the operation carried a positive or negative yield.  By looking at the transaction log, one can see that the strategy on both Air France was particualry unsuccessful because several short positions were opened (hence, with the 'expectation' of a fall in the prices), and were (forcibly) closed only 'at the end of the world' i.e. when we close the account and the portfolio at the end of our observed period, after prices had rather steadly surged. For LVHM we see a slightly different story, in which the first three couples of operations are three profitable buy and sell, after which the algorithms becomes inefficient and determines the same pattern as AIR.PA to be observed. Sanofi looks like the example of a successful implementation of our algorithm.

There are now some issues regarding our strategy that we would like to highlight, and that would require further inspection and study: 	

+ the first n days of observations (where n is the highest parameter value across all indicators making use of moving averages ) , should be left out. This is because during those n days only one out of two rules is implemented. This can clearly be source of biases. However, in this R framework , this option does not seem to be offered, since the input data is fed through the object `mktdata`, which is created automatically when applying the strategy;

+ no transaction fees are considered. Hence, any possible gain obtained by this strategy is in fact a gross profit;

+ the algorithm parameters were set by a 'thumb-rule' type of choice, i.e. no action was taken to determine whether any further restrictons were to be put in place to obtain a better strategy performance. For a better treatment on the code-related side of this matter, we refer the reader to @Trice2016 for a reference to parameter optimization and backtesting ;

+ no in-depth study on the market conditions over the six years observed was made, neither on the specific stocks cases.  Table 1 shows that the firms considered belong to four different industrial sectors - hence, some sector specificity may play a role in determining the evolution of prices;   

+ there is clearly the need for some constraints that prevent opening an excessive number of  short positions - especially when the algorithm returns signals contrasting with price trend.


One remark on Table 5: it is generated through `blotter::tradeStats`, and its output cannot be truncated. Moreover, the function developement seems unfinished, as one can notice from the uncomplete description of the statistics [^tradestats] .

[^tradestats]: Full account of the statistics here: https://rdrr.io/rforge/blotter/man/tradeStats.html

```{r act-stats, echo= FALSE, include = TRUE}
act.stats= read.csv(file="D:/2017-2018/data_analysis/technical_analysis/data/raw/act.stats.csv", 
         header= TRUE)

colnames(act.stats) <- 
  c("Measure", "AIR.PA","FP.PA","MC.PA","OR.PA","SAN.PA" )
pander::pander(act.stats, caption = "Startegy trading statistics", split.table= Inf, split.cells= c(3,2,2,2,2,2))
```


As one could have speculated by looking at the strategy log, only FP.PA and SAN.PA yield a positive return, under the active strategy we implemented. On the other hand, the three other stocks yield a negative return, with MC.PA being the worst among the three.


A quick glance at the risk measure indicator seems to suggest that a high volatility may have an implication on the accuracy of our automated trading strategy - indeed, AIR.PA and MC.PA were traded unprofitably, and their standard deviation is the highest. One may guess that the algorithm was thrown off by the frequent changes in prices. There is clearly the need for a more thorough analysis of these statistics, which however goes beyond the scope of our analysis. 


```{r act.rets, include= TRUE , echo= FALSE}
act.rets = read.csv(file="D:/2017-2018/data_analysis/technical_analysis/data/raw/act.rets.csv", 
         header=TRUE) 

colnames(act.rets) <- 
  c("Measure", "AIR.PA\nDailyEqPL","FP.PA\nDailyEqPL","MC.PA\nDailyEqPL","OR.PA\nDailyEqPL","SAN.PA\nDailyEqPL" )
pander::panderOptions('digits',4)
pander::panderOptions('round',3)
pander::pander(act.rets, caption= "Active strategy returns' statistics ", split.table= Inf)
```


Finally, we consider one very last measure of "fitness" of our startegy, which is by far the simplest: the level of capital left in our account, once all positions have been closed. We see from Figure 4 that the initial capital of €100000 has decreased to below €50000 (or $5e+04$). Moreover, there seems to be the need for a constraint on the capital invested, since towards the end of the observed period, one would actually get indebted. To our knowledge, one should hard-code an appropriate function to prevent more short positions being taken once the level of capital goes below zero.

![Account Capital level evolution of active positions]("D:/2017-2018/data_analysis/technical_analysis/report/equity_active.png")
<!-- change path on new machine -->

### Benchmarking with buy-and-hold strategy

The negative performance of our active portfolio strategy prompts the comparison with a passive strategy. We now implement a buy and hold strategy, over the same timeframe as before, with the same stocks we considered for our active strategy. Here we will allocate equal parts of the initial capital to each of the five stocks, and execute a buy order for each on the first day of observations. On the last day, we sell all the stocks we had bought. Thus, the increase(reduction) in the stock price will determine our gains(losses).


```{r 5.05, echo= FALSE}
source("D:/2017-2018/data_analysis/technical_analysis/michele/code_quantmod/5.05.rollout.R")

```

Since each stock price has risen during the five years examined, it can be easily noted that this buy and hold strategy appears rather profitable: our initial € 100.000 investment stake has increased by about 80%. At this stage, it is difficult to think that an active strategy could have beaten the market. On the other hand, an in-depth study is required to examine what factors determined such increases in prices - whether it was that these five companies were particularly successful, or perhaps the French economy was revamping after the financial crisis. This in turn highlights the importance of an appropriate market study that should accompany the creation of the trading strategy. Clearly, investing is far from gambling, and coding or mathemathical skills cannot make up for a poor understanding of the markets and the economy.

![Account Capital level evolution of long positions in B&H strategy ]("D:/2017-2018/data_analysis/technical_analysis/report/equity_BH.png")
<!-- change path on new machine -->
  

## Final comments and future steps
It is clear that our strategy implementation lacks of several important feautres, on which we already touched above. We left one important point untackled - namely, the absence of a proper testing strategy. As Guy Yollin illustrates [^yollin], implementing a trading strategy would first require the so-called *walk-forward analysis*, which allows for a dynamic parametrization of the model, with a lower impact of overfitting [^wfa_example].  Nevertheless, we would rather highlight the importance of having created a realistic model, which can constitute a first, solid building block towards a proper in-depth study of TA optimized applications to trading.


[^yollin]:http://www.r-programming.org/files	
[^wfa_example]: https://algotrading101.com/learn/what-is-walk-forward-optimization/

<!-- ## knitr and Rmarkdown -->
<!-- As a final remark, we would like to add that this report was created in Rmarkdown [^rmarkdown1] [^rmarkdown2]   and compiled with `knitr` [^knitr] and `pandoc` [^pandoc]. -->

<!-- [^rmarkdown1]:https://rmarkdown.rstudio.com/lesson-2.html -->
<!-- [^rmarkdown2]: https://bookdown.org/yihui/rmarkdown/ -->
<!-- [^knitr]: https://yihui.org/knitr/  -->
<!-- [^pandoc]:https://pandoc.org/ -->

<!-- not run -->
```{r bh.rets, eval= FALSE, echo=FALSE, include= FALSE }
bh.rets= read.csv(file="D:/2017-2018/data_analysis/technical_analysis/data/raw/bh.rets.csv",
  header= TRUE)

colnames(act.risk) <- 
  c("Measure", "AIR.PA\nDailyEqPL","FP.PA\nDailyEqPL","MC.PA\nDailyEqPL","OR.PA\nDailyEqPL","SAN.PA\nDailyEqPL" )
pander::panderOptions('digits',4)
pander::panderOptions('round',3)
pander::pander(bh.rets, caption= "Buy & Hold returns' statistics " )
```



\newpage    
# Neural networks
Neural networks (NN) is a "black box" technique that finds non-linear connections and recognize patterns between one or multiple inputs to generate an output [^ref1] . We will test a 1-input NN [^ref2]  and a multiple-input NN [^ref3]  in the attempt to predict the next-day stock price of our 5 stocks, over a period of 30 trading days, from the 16/11/2018 to the 31/12/2018. Based on the predictions, we will develop an investing strategy where everyday, for the above-mentioned 30 days, we will invest all our capital (starting at 10,000 euro) into the stock that will have the biggest predicted increase in price the next day, according to our model. Consequently, the next day we will sell all our stocks bought the previous day, and invest again all our capital with the same reasoning. In this analysis, all commission and brokerage fees are ignored.

[^ref1]:https://pathmind.com/wiki/neural-network
[^ref2]:http://rpubs.com/kapage/523169?fbclid=IwAR3RW_tVA_7SgCah7M0nmZL7anIL4gS_ZZ3dP_i_w8AOyQXoTMwXC_wQsoE
[^ref3]:https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/?fbclid=IwAR0z9tD0-WFxG3zVs8YmFaLF7RGnszbizQrhyGdyZG1-GL-D5coqBOnTiZE


## Benchmark
To evaluate the performance of the NN as an investment decision-maker, instead of using a ROC Curve, we decided to compare it with a diversified, long-term investment strategy, where the initial capital of 10.000 euro is invested equally in the 5 stocks (2.000 euro per stock) at the beginning of the period (16/11/2018) and all stocks are then sold at the end of the period (31/12/2018). 

```{r Benchmark strategy outcome, echo=FALSE, include= FALSE}
benchmark= read.csv(file="D:/2017-2018/data_analysis/technical_analysis/report/01.prediction.simple.csv",
         header= TRUE, dec = ","  )

colnames(benchmark) <- 
  c("Dates", "AIR.PA","FP.PA","MC.PA","OR.PA","SAN.PA"," ","Capital" )
pander::pander(benchmark, caption = "Benchmark strategy outcome",
               justify= "left", split.table= Inf, split.cells = c(15,3,3,3,3,3,15,15))
```


```{r  benchmark2, echo=FALSE, include= TRUE}
library(magrittr)
benchmark= read.csv(file="D:/2017-2018/data_analysis/technical_analysis/report/01.prediction.simple.csv",
                    header= TRUE, dec = ","  )

colnames(benchmark) <- 
  c("Dates", "AIR.PA","FP.PA","MC.PA","OR.PA","SAN.PA"," ","Capital" )

knitr::kable(benchmark, "latex", booktabs= TRUE,caption = "Benchmark strategy outcome", ) %>%
  kableExtra::row_spec(3, hline_after = TRUE) %>%
  kableExtra::kable_styling(latex_options="scale_down") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") 
```

As can be seen, the benchmark strategy has a return of -6%. Clearly, the higher the return of the NN-based investments, the more successful the NN algorithms will be. Moreover, in case of a return lower than -6% (lower than the "naive" strategy), the NN model will be considered as not useful in predicting stock prices.

## 1-input NN
The first NN model is a single hidden layer neural network. In this model there is one layer of input nodes that send weighted inputs to a subsequent layer of receiving nodes. The `nnetar` function in the forecast package fits a single hidden layer neural network model to a timeseries. The function model approach is to use lagged values of the time series as input data, reaching to a non-linear autoregressive model. The model takes as input the stock prices starting from the 31/12/2016 to 31/12/2018. The goal is to predict the stock prices between 16/11/2018 and 31/12/2018. 

<!-- Credit: http://rpubs.com/kapage/523169?fbclid=IwAR1LcmQ6zQ7Nx0FbMrQqQFml9QtJWx9_bybKAsKwWIPplCS60KBbpoDCElM -->

<!-- download file PREDICTION SIMPLE.xlsx -->

```{r eval= FALSE}

library(prophet)
library(quantmod)
library(forecast)
library(xlsx)
library(tseries)
library(timeSeries)
library(dplyr)
library(fGarch)
#Download the prices for the 5 stocks for the desired time frame
getSymbols("AI.PA", src="yahoo", from="2016-12-31", to="2018-12-31")
getSymbols("AIR.PA", src="yahoo", from="2016-12-31", to="2018-12-31")
getSymbols("BN.PA", src="yahoo", from="2016-12-31", to="2018-12-31")
getSymbols("BNP.PA", src="yahoo", from="2016-12-31", to="2018-12-31")
getSymbols("DG.PA", src="yahoo", from="2016-12-31", to="2018-12-31")

alpha <- 1.5^(-10)
```

We generate the predicted price of the 30 days for the 5 stocks with a `for` loop, where the prices are predicted one at the time. Although more computationally intense, in this way we are able to predict the price of the day given all the "information" available until the day before.

```{r eval= FALSE}
for (n in 1:30){
  close_price <- as.numeric(AIR.PA[1:479+n,'AIR.PA.Close'])
#Hidden layers creation
  alpha <- 1.5^(-10) 
  hn <- length(close_price)/(alpha*(length(close_price)+1))
#Fitting nnetar
  lambda <- BoxCox.lambda(close_price)
  dnn_pred <- nnetar(close_price, size= hn, lambda = lambda) 
  dnn_forecast <- forecast(dnn_pred, h= 1, PI = TRUE)   
  AIR.PA.P[n] = dnn_forecast[["mean"]] 
}

for (n in 1:30){
   close_price <- as.numeric(BN.PA[1:479+n,'BN.PA.Close'])
   hn <- length(close_price)/(alpha*(length(close_price)+1))
   lambda <- BoxCox.lambda(close_price)
   dnn_pred <- nnetar(close_price, size= hn, lambda = lambda)
   dnn_forecast <- forecast(dnn_pred, h= 1, PI = TRUE)
   BN.PA.P[n] = dnn_forecast[["mean"]]
 }
 
 #We run the same for loop above also for AI.PA, BNP.PA and DG.PA
 
```


We create a table with the predicted daily increase in price for every stock during the 30 days. After that, we will identify the stock with the highest predicted increase in price for every day. This will be the stock where to invest all 
the capital for the day.

```{r eval= FALSE}
AIR.LOL <- AIR.PA.P - as.numeric(AIR.PA[480:509,'AIR.PA.Close'])
BN.LOL <- BN.PA.P - as.numeric(BN.PA[480:509,'BN.PA.Close'])
BNP.LOL <- BNP.PA.P - as.numeric(BNP.PA[480:509,'BNP.PA.Close'])
DG.LOL <- DG.PA.P - as.numeric(DG.PA[480:509,'DG.PA.Close'])

df = data.frame(AI.LOL,AIR.LOL,BN.LOL,BNP.LOL,DG.LOL)

for (n in 1:30){
   if (max(df[n,]) == df[n,"AI.LOL"]){
   AI.DIF[n] = "AI.PA"
   } else if (max(df[n,]) == df[n,"AIR.LOL"]){
   AI.DIF[n] = "AIR.PA"
   } else if (max(df[n,]) == df[n,"BN.LOL"]){
   AI.DIF[n] = "BN.PA"
   } else if (max(df[n,]) == df[n,"BNP.LOL"]){
   AI.DIF[n] = "BNP.PA"
   } else if (max(df[n,]) == df[n,"DG.LOL"]){
   AI.DIF[n] = "DG.PA"
   }
}
```


<!-- See file "PREDICTION SIMPLE.xlsx" to see results of investment strategy based on the code above -->

```{r 1-input NN strategy outcome, echo=FALSE}
nn_one= read.csv(file="D:/2017-2018/data_analysis/technical_analysis/report/02.prediction.simple.csv",
         header= TRUE, dec = ","  )


colnames(nn_one) <- c("Day",	"Invest in",	"date",	"AI",	"AIR",	"BNP",	"BN",	"DG",	"#shares bought",	"€ Value "
)
pander::pander(nn_one, caption= "1-input NN strategy outcome", justify= "left", split.table= Inf, split.cells = c(1,2,4,2,2,2,2,2,3,4))


```


### Evaluation of 1-input NN
As can be seen, the investment strategy based on the 1-input NN has a return of +4%, which is an extremely good result considering the benchmark strategy return of -6%. This implies that, even though all the 5 stocks had negative performances during the time frame, the NN successfully identified the right stock at the right time, leading to a positive return.


## Multiple-input NN
The second NN model uses the `neuralnet` library for the analysis. It has 3 neurons in its hidden layer and the weights are calculated using a back propagation algorithm. The model takes several inputs that for simpliticy have been coded according to the following table:

```{r variables coding, echo=FALSE}
coding = read.csv(file="D:/2017-2018/data_analysis/technical_analysis/report/VariableCode.csv",
         header= TRUE, dec = ","  )

colnames(coding) <- c("Variable", "Identifier","Variable", "Identifier","Variable", "Identifier")
pander::pander(coding, caption= "Variables coding", justify= "left", split.table= Inf)




```


The goal is always to predict stock prices of the 30 days, hoping that the inclusion of additional variables like high price, low price, inflation and financial statements data will provide more accurate predictions.

<!-- Credits: https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/?fbclid=IwAR18hPVMs63r5YbqIzvmgVjxax_rk9Fi9SmrtBnw24hdxSy5EFTynvDaHOY -->


```{r eval= FALSE}
#Download "AI1.csv" "AIR1.csv" "BN1.csv" "BNP1.csv" 
#Download "DG1.csv" "PREDICTION SIMPLE.xlsx"
library(readr)
AI1 <- read_csv2("D:/2017-2018/data_analysis/technical_analysis/report/AI1.csv")
data <- AI1[, c(2:26)]
#we take all the data frame as training data to predict the next-day stock price
datatrain = data[ 1:1531, ]
datatest = data[ 1532, ]
#we normalize the values to avoid results based only on the disporportionate
#size of certain inputs
max = apply(data , 2 , max)
min = apply(data, 2 , min)
scaled = as.data.frame(scale(data, center = min, scale = max - min))
# install library
install.packages("neuralnet ")
#load library
library(neuralnet)
# creating training and test set
# the test set will be the closing price of a single day
# the training set will be all the data of the days before the day of the test set
trainNN = scaled[1:1531 , ]
testNN = scaled[1532 , ] 

```


We want to predict every next day price for the 5 stocks. But first, we want to check weather the the model gives more accurate results with or without the financial statement data as inputs.


```{r eval= FALSE}
# fit neural network
set.seed(2)
# Develop a NN model with tomorrow closing price as output and
# all the other variables (taken today) as input
NN = neuralnet( A1 ~ A2 + A3 + A4 + A5 + A6 + A7 + A8 + A9 + A10
+ A11 + A12 + A13 + A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21
+ A22 + A23 + A24 + A25, trainNN, hidden = 3 , linear.output = T ) 
# plot neural network
plot(NN)
```
In the image below we can see a graphical representation of the neuronal net: 
It has 3 neurons in its hidden layer. The black lines show the connections with weights. The weights are calculated using a back propagation algorithm. The blue line displays the bias term.

![Neuronal net representation](D:/2017-2018/data_analysis/technical_analysis/report/NNrep.png)

```{r eval= FALSE}
predict_testNN = compute(NN, testNN[,c(2:25)])
# We descale the output to obtain the results in the real scale
predict_testNN = (predict_testNN$net.result * (max(data$A1) - min(data$A1)))
+ min(data$A1)
# We create an array where to store the results per day for each stck
AI.P <- c()
# We run the model for every single day per stock, to predict the prices 
# one by one
View(predict_testNN)
for (n in 1:30){
  datatrain = data[ 1:1501+n, ]
  datatest = data[ 1502+n, ]
  max = apply(data , 2 , max)
  min = apply(data, 2 , min)
  scaled = as.data.frame(scale(data, center = min, scale = max - min))
  trainNN = scaled[1:1501+n , ]
  testNN = scaled[1502+n , ]
# model with financial statements data
  NN = neuralnet(A1 ~ A2 + A3 + A4 + A5 + A6 + A7 + A8 + A9 + A10
  + A11 + A12 + A13 + A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21
  + A22 + A23 + A24 + A25, trainNN, hidden = 3 , linear.output = T )
  predict_testNN = compute(NN, testNN[,c(2:25)])
  predict_testNN = (predict_testNN$net.result * (max(data$A1) - min(data$A1)))
  + min(data$A1)
  AI.P[n] <- predict_testNN
}
AI.P2 <- c()
for (n in 1:30){
  datatrain = data[ 1:1501+n, ]
  datatest = data[ 1502+n, ]
  max = apply(data , 2 , max)
  min = apply(data, 2 , min)
  scaled = as.data.frame(scale(data, center = min, scale = max - min))
  trainNN = scaled[1:1501+n , ]
  testNN = scaled[1502+n , ]
# model without financial statements data
  NN = neuralnet(A1 ~ A2 + A3 + A4 + A5 + A6 + A7 + A8 + A9 + A10,
  trainNN, hidden = 3 , linear.output = T )
  predict_testNN = compute(NN, testNN[,c(2:10)])
  predict_testNN = (predict_testNN$net.result * (max(data$A1) - min(data$A1)))
  + min(data$A1)
  AI.P2[n] <- predict_testNN
}
# Calculate Root Mean Square Error (RMSE)
Reals <- data[1503:1532,1]
RMSE <- sqrt(sum((Reals-AI.P)^2)) # RMSE = 6.072
RMSE2 <- sqrt(sum((Reals-AI.P2)^2)) # RMSE2 = 6.064
```


As can be seen, the model without the financial statement variables (RMSE = 6.072) is more accurate than the model with them (RMSE2 = 6.064) according to the RMSE value. Hence, we will continue without taking into account the financial statement variables.

```{r eval= FALSE}
#We predict the prices of the other 4 stocks one by one,
#without the financial statement variables as input
library(readr)
AIR1 <- read_csv2("D:/2017-2018/data_analysis/technical_analysis/data/AIR1.csv")
data <- AIR1
AIR.P2 <- c()
for (n in 1:30){
  datatrain = data[ 1:1501+n, ]
  datatest = data[ 1502+n, ]
  max = apply(data , 2 , max)
  min = apply(data, 2 , min)
  scaled = as.data.frame(scale(data, center = min, scale = max - min))
  trainNN = scaled[1:1501+n , ]
  testNN = scaled[1502+n , ]
  NN = neuralnet(A1 ~ A2 + A3 + A4 + A5 + A6 + A7 + A8 + A9 + A10,
  trainNN, hidden = 3 , linear.output = T )
  predict_testNN = compute(NN, testNN[,c(2:10)])
  predict_testNN = (predict_testNN$net.result * (max(data$A1) - min(data$A1)))
  + min(data$A1)
  AIR.P2[n] <- predict_testNN
}
#We run the same for loop above also for BN.PA, BNP.PA and DG.PA
```

We want to create a table with the predicted daily increase in price for every stock during the 30 days. After that, we will identify the stock with the highest predicted increase in price for every day. This will be the stock where to invest all the capital for the day.

```{r eval= FALSE}
AI.R <- AI1[1502:1531, c(2)]
AIR.R <- AIR1[1502:1531, c(1)]
BN.R <- BN1[1502:1531, c(1)]
BNP.R <- BNP1[1502:1531, c(1)]
DG.R <- DG1[1502:1531, c(1)]
AI.DIF <- AI.P2 - AI.R
AIR.DIF <- AIR.P2 - AIR.R
BN.DIF <- BN.P2 - BN.R
BNP.DIF <- BNP.P2 - BNP.R
DG.DIF <- DG.P2 - DG.R
df = data.frame(AI.DIF,AIR.DIF,BN.DIF,BNP.DIF,DG.DIF)
#identify the stock with the highest predicted increase in price for every day
X <- c()
for (n in 1:30){
  if (max(df[n,]) == df[n,"A1"]){
    X[n] = "AI.PA"
  } else if (max(df[n,]) == df[n,"A1.1"]){
    X[n] = "AIR.PA"
  } else if (max(df[n,]) == df[n,"A1.2"]){
    X[n] = "BN.PA"
  } else if (max(df[n,]) == df[n,"A1.3"]){
    X[n] = "BNP.PA"
  } else if (max(df[n,]) == df[n,"A1.4"]){
    X[n] = "DG.PA"
  }
}

```


<!-- see file "PREDICTION SIMPLE.xlsx" for the investment strategy outcome -->

```{r multiple input NN strategy outcome, echo=FALSE}
nn_mult= read.csv(file="D:/2017-2018/data_analysis/technical_analysis/report/03.prediction.simple.csv",
         header= TRUE, dec = ","  )


colnames(nn_mult) <- c("Day",	"Invest in",	"date",	"AI",	"AIR",	"BNP",	"BN",	"DG",	"#shares bought",	"€ Value "
)
pander::pander(nn_mult, caption= "Multiple-input NN strategy outcome", justify= "left", split.table= Inf)

```


### Evaluation of Multiple-input NN

As can be seen, the multiple-input based investment has a return of -7%. This shows that this method cannot be used to predict stock prices. We believe this is because the method predicts prices based on just the previous-day values of several variables, hence without considering the time-serie behind the price trend. Instead, the 1-input NN took into account the whole trend of the prices during the previous 1 year and a half.

## Neuronal Network Conclusion

To conclude, we can argue that the 1-input NN could be used to invest in stocks. We recommend to further test and validate this method over a larger number of stocks (100) and over a longer time frame (1 year of predicted prices) before investing in real life with this model.


\newpage
# Random forest

*Random forest* is "a predictor consisting of a collection of randomized base regression trees" (@Biau2012 (p. 2)) , which determine in expectation the estimate of a random parameter.
In our framework,  random forest is used for stock price prediction. This is a supervised learning that randomly creates and merges multiple decision trees into one common forest. The benefit of this technique is that, rather than relying on a single tree, it combines all the trees at once, giving the optimum result. 

The basic training principle of decision trees is the recursive partitioning of the feature space using a tree structure, where each root node is split until pure nodes, i.e nodes which contain samples of a single class, are achieved (to @Denil2014).

## Why Random Forest?

As it is termed as one of the easiest machine learning algorithms according to @HibaSadia2019, it gives accurate results and reduces overfitting of the model with a good accuracy in the prediction. Nonetheless, given the high volatility and instability in the stock markets, prediction has become very challenging. The random forest algorithm randomly selects different observations and features to build several decision trees and then takes aggregate of all the decision trees. It can be classified into two types: classification and regression. In our model, we are doing a regression based on some continuous variables that might have a relevant effect on stock prices.

## Methodology

70% of the data is used to train the model and 30% is used to test it. The basic approach of the model is to learn the pattern and relationships in the data from the training set and then to reproduce it in the test set. In this model, we are computing the random forest regression by considering 19 variables that could affect the stock closing prices. 



![Flow chart of the process](D:/2017-2018/data_analysis/technical_analysis/report/rflow.png)

### Summarizing the Data
  
To begin with, we import the data of all the 5 stock prices from Yahoo finance. In order to have a summary of the data we use different functions such as `summary`,  which is a generic function used to produce result summaries of various model fitting functions. Then we use the `str` function, which is a solid way to display the structure of an R object. `str` will give the output of the information on one line for each basic structure. The `dim` function gives the number of dimensions in the data. 

This file shows all the prices of Air Liquide with all the 19 variables for six years, from 2013-2018. 

```{r eval= FALSE}
##Air Liquide

AI_FINALDATA

dim(AI_FINALDATA)    #dimension of the matrix
summary(AI_FINALDATA)  #summary of the data
str(AI_FINALDATA)  #structure of the data

```


```{r echo= FALSE }
  AI.PA= 
    read.csv("D:/2017-2018/data_analysis/technical_analysis/report/AI_FINALDATA.csv")
```

Therefore, the above code just gives an idea about the dataset which we will be using in our model. 


###  Training the machine

This phase consists of feeding the algorithm with the training data so that the model can understand the  pattern of the data. Here is the code for dividing the data into train and test data. Before dividing, we need some packages which are required to get the result we want. 


```{r eval= FALSE}
library(party)
#install caret package
install.packages('caret')
#load package
set.seed(123)
library(caret)
trainAI = createDataPartition(AI_FINALDATA$AI.PA.Close,
                                 p=0.7, list=FALSE,times=1)

train_1 = AI_FINALDATA[1:1075,]    #1075 obs out of 1533
test_1 = AI_FINALDATA[1076:1533,]    #458 obss out of 1533
```

`party` (library) - used for recursive partitioning 

`caret` - (Classification And Regression Training) is a set of functions that attempt to streamline the process for creating predictive models. This package is very important for dividing the data into two.

`set.seed` - Set the seed of R's random number generator, which is useful for creating simulations or random objects that can be reproduced.

`createDataPartition` - A series of test/training partitions are created using createDataPartition while createResample creates one or more bootstrap samples. The main function which is used to split the data.

Now we will use these two datasets for predicting the stock prices and applying the random forest algorithm.


###  Data Scoring

The method of applying a predictive model to a dataset is called the scoring data process according to @HibaSadia2019. The last part of this module describes how the result of the model can infer whether a stock will rise or sink, based on certain parameters. It also shows the vulnerabilities of a particular stock or entity. 

```{r eval= FALSE}
#random forest parameters
#fitting the model or creating the forest
library(randomForest)
output.forestAI <- randomForest(AI.PA.Close ~  Interest.rates + 
ExchangeRate + PoliticalStability + Infaltion + AirLiquideDividend 
+ REVENUE + NET.INCOME + Basic.earnings.per.share + Diluted.earnings.per.share 
+ TOTAL.ASSETS  + INTANGIBLE.ASSETS + PPE + CASH  +  TOTAL.EQUITY 
+ NON.CURRENT.LIABILITY + Cash.flows.from.operating.activities + 
Net.cash.flows.from.investing.activities + 
Net.cash.flows.from.financing.activities + 
Net.cash.and.cash.equivalents, train_1)

# View the forest results.
print(output.forestAI) 
```

`mtry` = number of variables selected at each split.
lower `mtry` means less correlation between trees 

`randomForest`(library) -  implements Breiman's random forest algorithm (based on Breiman and Cutler's original Fortran code) for classification and regression. It can also be used in unsupervised mode for assessing proximities among data points.

the output gives an object of class randomForest, which is a list with the following components:


`call`:the original call to randomForest

`type`: regression

`predicted`: the predicted values of the input data based on out-of-bag samples.

Type of random forest: regression
Number of trees: 500
No. of variables tried at each split: 6

From the plot we can observe that in the case of Air Liquide, Interest rate has a significant impact on closing price.


```{r eval= FALSE}
VI_F=importance(output.forestAI)

VI_F

write.csv(VI_F , "VI_FAI.csv")


varImpPlot(output.forestAI,type=2)

```

![Random Forest of Air Liquide](D:/2017-2018/data_analysis/technical_analysis/report/AI.Plot.png)


```{r echo= FALSE, include=FALSE }
  AI.PA= 
    read.csv("D:/2017-2018/data_analysis/technical_analysis/report/VI_FAIRBUS.csv")
```

`IncNodePurity` relates to the loss function that determines how splits are chosen.

`importance` - A matrix that measures the importance of each predictor variable. Columns show different measures of importance.
`varImplot` - the importance of the variables that were plotted.

The result we get by VI_F is that again Interest rate is the factor by which we get the best splits to understand our data.

###  Experimental Results

Now, with the help of our random forest and datasets , we will predict the future prices and we will check how accurate are the results. This will be done by getting a confusion matrix. A confusion matrix  calculates a cross-tabulation of observed and predicted classes with associated statistics. In short, it compares the actual values and the predicted values so that we can get to know how reliable are our predictions. 

```{r eval=FALSE}
#Predictions

PredictionsAdjusted <- predict(output.forestAI, test_1, type='response')
t <- table(predictions=PredictionsAdjusted, actual=test_1$AI.PA.Close)
t
write.csv(t , "ConfusionMatrix_AI.csv")

```

This gives the Confusion Matrix for Air Liquide. 

```{r  eval=FALSE, echo= FALSE, include=FALSE }
  AI.PA= 
    read.csv("D:/2017-2018/data_analysis/technical_analysis/report/ConfusionMatrix_AI.csv")
```

```{r eval=FALSE}
#Accuracy Metric
sum(diag(t))/sum(t)
```

The accuracy metric in random forest gives the percentage of how accurate the predictions are. In our case, the accuracy metric is given below:

```{r eval= FALSE}
Accuracy Metric: 0.01310044 # or 1.31%
```

 This has a very low value which means that we are only 1% accurate in predicting our prices. The reason behind this low accuracy rate is that we have only considered a few variables, as in the real life scenario there are many variables including the opening, high and low prices of the same day, which are ignored in this case. Furthermore, there are other variables which cannot be quantified leading to lack of accuracy. However, another reason is that with an increase in the number of trees and `mtry` (number of splits) we increase the overfitting and complexity of the model which leads to low accuracy. 
 
```{r eval=FALSE}
#high strength of tree =Low error rate of individual tree classifier

PredictionWithProbs <- predict(output.forestAI, test_1, type = "response")
PredictionWithProbs 		#predicting stock prices for 458 days
write.csv(t , "PredictionsPrices_AI.csv")

```

```{r  eval=FALSE, include= FALSE }
  AI.PA= 
    readr::read_csv("D:/2017-2018/data_analysis/technical_analysis/report/
    PredictionsPrices_AI.csv")
```

This function gives 458 predicted values on the basis of the train data of 1075 observations. This data can be used to develop a trading strategy where we decide where to invest based on the predictions.

```{r eval=FALSE}
# to find the best "mtry": m try means number of splits at each point. 
bestmtryAI <- tuneRF(train_1,train_1$AI.PA.Close, ntreeTry = 200,
stepFactor = 1.5, improve = 0.01, trace = T, plot= T)
```       

`OOB Error` : Out-of-bag error, also called out-of-bag estimate, is a method to measure the prediction error of random forests, boosted decision trees. 

![OOB Error of Air Liquide](D:/2017-2018/data_analysis/technical_analysis/report/AI.OBB.png)

```{r  eval=FALSE, include=FALSE}
  AI.PA= 
    readr::read_csv("D:/2017-2018/data_analysis/technical_analysis/report/OOB_AI.csv")
```


We saw the whole alogrithm applied on the dataset of Air Liquide with 5 years data. Now, we will repeat all the steps above for all other 4 stocks and we will interpret the results for all of them. The output given below shows the results for the other stocks by using the same code applied for Air Liquide. 


![RANDOM FOREST AND OOB ERRORS FOR AIRBUS AND BNP PARIBAS](D:/2017-2018/data_analysis/technical_analysis/report/AIR_BNP.Plot.png)

![RANDOM FOREST AND OOB ERRORS FOR DANONE AND VINCI](D:/2017-2018/data_analysis/technical_analysis/report/DANONE_VINCI.Plot.png)

##  Investment strategy

In general, the accuracy level of our model is very low for all the five stocks. Nonetheless, to have a clearer view on its performance, we will develop an investment strategy based on it and analyze the results. The graph below compares the predictions of the 5 stocks from 15/03/2017 to 31/12/2018.

![Predictions of All the 5 Stocks](D:/2017-2018/data_analysis/technical_analysis/report/Predictions.Combined.png)

```{r  eval=FALSE, include=FALSE}
  Predictions= 
    readr::read_csv("D:/2017-2018/data_analysis/technical_analysis/report/Combined.Predictions.csv")
```
 
The investing strategy executed is the same one used in Part 4 for the neuronal network models. We buy today the stock that, according to our model, will have the higher increase in price tomorrow, and sell the stock the day after, repeating the process every day.

The benchmark strategy consists of a diversified buy and hold investment:

```{r  eval=TRUE,echo= FALSE, include=TRUE }
combined <- read.csv(
  "D:/2017-2018/data_analysis/technical_analysis/report/Combined.Predictions.Tables.csv")

pander::pander(combined, caption = "Diversified Strategies",
               justify= "left", split.table= Inf) 
``` 

The table above shows the diversified strategy according to which, we would get a negative return on our investment of -0.018. This implies that the diversified strategy would result in a loss for the investor. 

The file PA contains all the predictions we found out from 15/03/2017 to 31/12/2018 for all the 5 stocks.
The file DAT contains all the real closing prices of all the 5 stocks from 14/03/2017 to 28/12/2018.
In the code below, we first calculate the predicted day-by-day returns for the 5 stocks and then simulate an investing strategy where we buy everyday the stock with the highest predicted return, and sell it the day after.

```{r eval=FALSE}
PA
DAT

RETU <- (PA-DAT)/DAT
View(RETU)
I <- c()
for (n in 1:458){
    if (max(RETU[n,]) == RETU[n,1]){
        I[n] = 1
    } else if (max(RETU[n,]) == RETU[n,2]){
        I[n] = 2
    } else if (max(RETU[n,]) == RETU[n,3]){
        I[n] = 3
    } else if (max(RETU[n,]) == RETU[n,4]){
        I[n] = 4
    } else if (max(RETU[n,]) == RETU[n,5]){
        I[n] = 5
    }
}
X = 10000
for (n in 1:456){
    if (I[n] == 1){
        Y = 1
    } else if (I[n] == 2){
        Y = 2
    } else if (I[n] == 3){
        Y = 3
    } else if (I[n] == 4){
        Y = 4
    } else if (I[n] == 5){
        Y = 5
    }
    X = X*(DAT[n+2,Y]/DAT[n+1,Y])
}
View(X)   


```

We see that, following the random forest algorithm, starting with 10,000 euro, we would end up with 10014.39 euro after 1 year and 8 months of trading. This shows that the strategy outperforms the passive investment but a return of 0.14% after 20 months is far from being an ideal scenario.


##  Comments and Future Implementation

Future steps for this analysis would be to get rid of drawbacks of the model and try to attain a higher level of accuracy by using more complex random forest functions and adding other parameters which could impact price. The additional use of traditional algorithms and data mining techniques could also improve the predictability power of the model.


\newpage
# References 
